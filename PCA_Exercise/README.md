# Dimensionality Reduction


## Project Intro
The purpose of this project is to reduce dimensions on the Swiss dataset using Principal Component Analysis algorithm (PCA).

### Methods Used
* Data Preparation
* Dimensionality Reduction
* Visualization

### Technologies
* [Python](https://www.python.org/)
* [Pandas](https://pandas.pydata.org/)
* [Matplotlib](https://matplotlib.org/)
* [Seaborn](https://seaborn.pydata.org/)
* [Scikit-learn](https://scikit-learn.org/stable/)

## Project Description
Dimensionality reduction  will reduce the model's complexity and also remove some noise in the data. In this way, it helps to mitigate overfitting.Dimensionality reduction is common in fields that deal with large numbers of observations or large numbers of variables.

Principal Component Analysis algorithm is one of the most common algorithms that can transform the data into a low dimensional space.

The explained variance ratio:

![here](https://github.com/Unisepp/Data_Mining_Exercises/blob/main/PCA_Exercise/fig1.png)

By visualizing the results it can be shown that there is a clear seperation on the data.

![here](https://github.com/Unisepp/Data_Mining_Exercises/blob/main/PCA_Exercise/fig2.png)

## Getting Started


1. Download and install python on your computer
2. Make sure to install libraries that have been mentioned before in the 'Technologies' section of the text, if you don't already have them
3. You can either directly download this repo or clone it (for help see this [tutorial](https://help.github.com/articles/cloning-a-repository/)) 
4. The Swiss dataset is stored [here](https://github.com/Unisepp/Data_Mining_Exercises/blob/main/PCA_Exercise/swiss.csv)
5. Data processing and transformation scripts are being kept [here](https://github.com/Unisepp/Data_Mining_Exercises/blob/main/PCA_Exercise/PCA_Exercise.py)
6. Run the code in python and see the results



